{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexa Kozachok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"c:\\knu\\piton4\")\n",
    "from bn256 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Alexa_Hamming:\n",
    "    #using standart Python integer type\n",
    "\n",
    "    @staticmethod\n",
    "    def get_random_vector_of_minusOneAndOnes(xSize = 16):\n",
    "        return [random.randrange(-1, 2, 2) for xIndex in range(xSize)]\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_of_types(*args):\n",
    "        xSet_of_types = set([])\n",
    "        for arg in args:\n",
    "            xSet_of_types.add(type(arg))\n",
    "        return xSet_of_types\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_iterable_object(arg):\n",
    "        try:\n",
    "            iterator = iter(arg)\n",
    "            #print(arg, 'is iterable')\n",
    "            return True\n",
    "        except TypeError as iterator_error:\n",
    "            #print(arg, 'is not iterable')\n",
    "            return False\n",
    "        \n",
    "    @staticmethod\n",
    "    def is_iterable(*args):\n",
    "        for arg in args:\n",
    "            if Alexa_Hamming.is_iterable_object(arg):\n",
    "                pass\n",
    "            else:\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    @staticmethod\n",
    "    def is_size_the_same(*args):\n",
    "        xSet_of_sizes = set([])\n",
    "        for arg in args:\n",
    "            xSet_of_sizes.add(len(arg))\n",
    "        if 1 == len(xSet_of_sizes):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def inner_product(xVec1, xVec2):\n",
    "        xSigned_inner_product = 0\n",
    "        for i in range(len(xVec1)):\n",
    "            xSigned_inner_product += (xVec1[i]*xVec2[i])\n",
    "        return xSigned_inner_product\n",
    "    \n",
    "    @staticmethod\n",
    "    def different_bits_via_inner_product(xVec1, xVec2):\n",
    "        return ((len(xVec1) - Alexa_Hamming.inner_product(xVec1, xVec2)) // 2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def hamming_distance(xVec1, xVec2, xType = list):\n",
    "        assert Alexa_Hamming.is_iterable(xVec1, xVec2), \\\n",
    "        \"at least one of arg is not iterable object (could not be a vector)\"\n",
    "        assert set([xType]) == Alexa_Hamming.set_of_types(xVec1, xVec2), \\\n",
    "        \"objects are of different types or function needs other types of vectors\"\n",
    "        assert Alexa_Hamming.is_size_the_same(xVec1, xVec2), \\\n",
    "        \"the size (length) of args (vectors) are not the same\"\n",
    "        xSize = len(xVec1)\n",
    "        return (Alexa_Hamming.different_bits_via_inner_product(xVec1, xVec2)/xSize)\n",
    "\n",
    "    @staticmethod\n",
    "    def hamming_distance_typeList_fast(xVec1, xVec2, xSize = 16):\n",
    "        return ((xSize - sum([xVec1[i]*xVec2[i] for i in range(xSize)])) / (2*xSize))\n",
    "    \n",
    "    @staticmethod\n",
    "    def hamming_distance_typeList_length16_fast(xVec1, xVec2):\n",
    "        return ((16 - sum([xVec1[i]*xVec2[i] for i in range(16)])) / 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "G1_generator = copy.deepcopy(curve_G)\n",
    "G2_generator = copy.deepcopy(twist_G)\n",
    "G1 = copy.deepcopy(g1_scalar_base_mult(1))\n",
    "G2 = copy.deepcopy(g2_scalar_base_mult(1))\n",
    "invG1  = G1.scalar_mul(gfp_1(order-1).value())\n",
    "invG2 = copy.deepcopy(G2)\n",
    "invG2.negate()\n",
    "#========================================\n",
    "alpha = rand_elem()\n",
    "beta  = rand_elem()\n",
    "H1 = copy.deepcopy(g1_scalar_base_mult(alpha))\n",
    "H2 = copy.deepcopy(g2_scalar_base_mult(beta))\n",
    "invH1  = H1.scalar_mul(gfp_1(order-1).value())\n",
    "invH2 = copy.deepcopy(H2)\n",
    "invH2.negate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True : G1_generator.is_on_curve() \n",
      "True : G2_generator.is_on_curve() \n",
      "True : G1.is_on_curve() \n",
      "True : G2.is_on_curve() \n",
      "True : invG1.is_on_curve() \n",
      "True : invG2.is_on_curve() \n",
      "False : g1_add(G1, invG1).is_on_curve() \n",
      "False : g2_add(G2, invG2).is_on_curve() \n",
      "True : H1.is_on_curve() \n",
      "True : H2.is_on_curve() \n",
      "True : invH1.is_on_curve() \n",
      "True : invH2.is_on_curve() \n",
      "False : g1_add(H1, invH1).is_on_curve() \n",
      "False : g2_add(H2, invH2).is_on_curve() \n"
     ]
    }
   ],
   "source": [
    "print(\"%s : G1_generator.is_on_curve() \" % G1_generator.is_on_curve())\n",
    "print(\"%s : G2_generator.is_on_curve() \" % G2_generator.is_on_curve())\n",
    "print(\"%s : G1.is_on_curve() \" % G1.is_on_curve())\n",
    "print(\"%s : G2.is_on_curve() \" % G2.is_on_curve())\n",
    "print(\"%s : invG1.is_on_curve() \" % invG1.is_on_curve())\n",
    "print(\"%s : invG2.is_on_curve() \" % invG2.is_on_curve())\n",
    "print(\"%s : g1_add(G1, invG1).is_on_curve() \" % g1_add(G1, invG1).is_on_curve())\n",
    "print(\"%s : g2_add(G2, invG2).is_on_curve() \" % g2_add(G2, invG2).is_on_curve())\n",
    "#========================================\n",
    "print(\"%s : H1.is_on_curve() \" % H1.is_on_curve())\n",
    "print(\"%s : H2.is_on_curve() \" % H2.is_on_curve())\n",
    "print(\"%s : invH1.is_on_curve() \" % invH1.is_on_curve())\n",
    "print(\"%s : invH2.is_on_curve() \" % invH2.is_on_curve())\n",
    "print(\"%s : g1_add(H1, invH1).is_on_curve() \" % g1_add(H1, invH1).is_on_curve())\n",
    "print(\"%s : g2_add(H2, invH2).is_on_curve() \" % g2_add(H2, invH2).is_on_curve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 = \n",
      "\t[-1, 1, -1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1, 1, -1, 1]\n",
      "v2 = \n",
      "\t[-1, 1, 1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#3. Generate two vectors v1, v2 of [-1, 1] with length 16 \n",
    "v1 = Alexa_Hamming.get_random_vector_of_minusOneAndOnes()\n",
    "v2 = Alexa_Hamming.get_random_vector_of_minusOneAndOnes()\n",
    "print(\"v1 = \\n\\t{0}\".format(v1))\n",
    "print(\"v2 = \\n\\t{0}\".format(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([v1[i]*v2[i] for i in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alexa_Hamming.inner_product(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alexa_Hamming.hamming_distance(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "mskT = collections.namedtuple('mskT',     ['h_g1', 's_vector', 't_vector', 'h_g2', 'u_vector', 'v_vector'])\n",
    "#xMsk = mskT._make((gen1_h, s_vector, t_vector, gen2_h, u_vector, v_vector))\n",
    "#========================================\n",
    "class Alexa_IPE_Setup:\n",
    "    \n",
    "    def __init__(self, n, g1, g2, h1, h2, inv_g1 = None, inv_g2 = None):\n",
    "        self.n  = n\n",
    "        self.G1 = g1\n",
    "        self.G2 = g2\n",
    "        self.H1 = h1\n",
    "        self.H2 = h2\n",
    "        self.invG1 = inv_g1\n",
    "        self.invG2 = inv_g2\n",
    "        self.msk = Alexa_IPE_Setup.get_msk(self.n, self.G1, self.G2, self.H1, self.H2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_msk(n, g1, g2, h1, h2):\n",
    "        s_vector = [ rand_elem() for i in range(n) ]\n",
    "        t_vector = [ rand_elem() for i in range(n) ]\n",
    "        u_vector = [ rand_elem() for i in range((n+2)) ]\n",
    "        v_vector = [ rand_elem() for i in range((n+2)) ]\n",
    "        gen1_h = [ g1_add(G1.scalar_mul(s_vector[i]), h1.scalar_mul(t_vector[i])) for i in range(n) ]\n",
    "        gen2_h = [ g2_add(G2.scalar_mul(u_vector[i]), h2.scalar_mul(v_vector[i])) for i in range((n+2)) ]\n",
    "        return mskT._make((gen1_h, s_vector, t_vector, gen2_h, u_vector, v_vector))\n",
    "    \n",
    "    @staticmethod\n",
    "    def oneToGminusOneToInvG(xOneminusOne, G, invG):\n",
    "        assert xOneminusOne in [-1,1], \" def oneToG1minusOneToInvG1(xOneminusOne, G, invG): argument type|range ERROR \"\n",
    "        if -1 == xOneminusOne:\n",
    "            return invG\n",
    "        else:\n",
    "            return G\n",
    "        \n",
    "    @staticmethod\n",
    "    def vectorOfNumberToVectorOfPoints(xVector, G, invG):\n",
    "        assert set(xVector).issubset(set([-1,1])), \" ERROR \"\n",
    "        return [ Alexa_IPE_Setup.oneToGminusOneToInvG(xElement, G, invG) for xElement in xVector ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAlexa_IPE_Setup = Alexa_IPE_Setup(len(v1), G1, G2, H1, H2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1_as_points = Alexa_IPE_Setup.vectorOfNumberToVectorOfPoints(v1, G2, invG2)\n",
    "v2_as_points = Alexa_IPE_Setup.vectorOfNumberToVectorOfPoints(v2, G1, invG1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###5. IPE: Registration:\n",
    "######5.1. Generate random number r0\n",
    "######5.2. Init array 'reg_template' of points with length 16 + 4.\n",
    "######5.3. Calculate reg_template[0] = r0 * G2\n",
    "######5.4. Calculate reg_template[1] = r0 * H2\n",
    "######5.5. Calculate for reg_template[2:18+2] = r0 * gen2_h[i], where i = 0 to 18\n",
    "######5.6. Calculate for reg_template[2] = reg_template[2] - s[i] * v1points[i], where i = 0 to 16\n",
    "######5.7. Calculate for reg_template[3] = reg_template[3] - t[i] * v1points[i], where i = 0 to 16\n",
    "######5.8. Calculate for reg_template[4:16+4] = reg_template[4:16+4] + v1points[i], where i = 0 to 16\n",
    "######5.9. reg_template is your encrypted bio template for registration\n",
    "\n",
    "class Alexa_IPE_Registration:\n",
    "    #Alexa_IPE_Registration(xMsk, v1_as_points, 16)\n",
    "    \n",
    "    def __init__(self, msk, c_vector, n):\n",
    "        self.msk = msk\n",
    "        self.c = c_vector\n",
    "        self.n = n\n",
    "        self.r0 = rand_elem()\n",
    "        self.reg_template = []\n",
    "        self.reg_template.append(G2.scalar_mul(self.r0))\n",
    "        self.reg_template.append(H2.scalar_mul(self.r0))\n",
    "        self.h2 = self.msk.h_g2\n",
    "        self.reg_template += [xElement.scalar_mul(self.r0) for xElement in self.h2 ]\n",
    "        #\n",
    "        self.powers = self.msk.s_vector\n",
    "        self.ProductTemp = \\\n",
    "        Alexa_IPE_Registration.akaProduct_g2(self.c, self.powers, 0, n, 0, 0)\n",
    "        self.reg_template[2] = g2_add(self.reg_template[2], self.ProductTemp.scalar_mul(order-1))\n",
    "        #\n",
    "        self.powers = self.msk.t_vector\n",
    "        self.ProductTemp = \\\n",
    "        Alexa_IPE_Registration.akaProduct_g2(self.c, self.powers, 0, n, 0, 0)\n",
    "        self.reg_template[3] = g2_add(self.reg_template[3], self.ProductTemp.scalar_mul(order-1))\n",
    "        #\n",
    "        for i in range(0, 16, 1):\n",
    "            self.reg_template[i+4] = g2_add(self.reg_template[i+4], self.c[i])\n",
    "           \n",
    "    @staticmethod            \n",
    "    def akaProduct_g2(c_vector, power_vector, j, n, shift_c_index = 0, shift_power_index = 0):\n",
    "        xAkaProduct = c_vector[j + shift_c_index].scalar_mul(power_vector[j + shift_power_index])\n",
    "        for i in range((1+j), n, 1):\n",
    "            temp = c_vector[i + shift_c_index].scalar_mul(power_vector[i + shift_power_index])\n",
    "            xAkaProduct = g2_add(xAkaProduct, temp)\n",
    "            del temp\n",
    "        return xAkaProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAlexa_IPE_Registration = Alexa_IPE_Registration(xAlexa_IPE_Setup.msk, Alexa_IPE_Setup.vectorOfNumberToVectorOfPoints(v1, G2, invG2), len(v1))\n",
    "assert len(xAlexa_IPE_Registration.reg_template) == (4 + len(v1)), \" somthing wrong \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "###6. IPE: Authentication:\n",
    "######6.1. Generate random number r0 (it is another r0 then in previous step)\n",
    "######6.2. Init array 'auth_template' of points with length 16 + 4.\n",
    "######6.3. Init auth_template[0,1] = 0 * G1 (we get 'infinitive points O, we will use in to add other points: O + P1 = P1')\n",
    "######6.4. Calculate auth_template[2] = r0 * G1\n",
    "######6.5. Calculate auth_template[3] = r0 * H1\n",
    "######6.6. Calulate auth_template[4: 16+4] = (r0 * gen1_h[i]) + v2points[i], where i = 0 to 16\n",
    "######6.7. Calculate for auth_template[0] = auth_template[0] - (u[i] * auth_template[i + 2]), where i = 0 to 16+2\n",
    "######6.8. Calculate for auth_template[1] = auth_template[1] - (v[i] * auth_template[i + 2]), where i = 0 to 16+2\n",
    "######6.9. auth_template is your encrypted bio template for authentication\n",
    "######6.10. Calculate Inner Product Encryption using reg_template and auth_template:\n",
    "############6.10.1. e *= pairing(reg_template[i], auth_template[i]), where i = 0 to 16+4\n",
    "############6.11.2. Next task is 8 after generate table of powers in taks 7.\n",
    "\n",
    "class Alexa_IPE_Authentication:\n",
    "    \n",
    "    def __init__(self, msk, c_vector, n):\n",
    "        self.msk = msk\n",
    "        self.c = c_vector\n",
    "        self.n = n\n",
    "        self.r0 = rand_elem()\n",
    "        self.auth_template = []\n",
    "        self.G1zero = G1.scalar_mul(0)\n",
    "        self.auth_template.append(self.G1zero)\n",
    "        self.auth_template.append(self.G1zero)\n",
    "        self.auth_template.append(G1.scalar_mul(self.r0))\n",
    "        self.auth_template.append(H1.scalar_mul(self.r0))\n",
    "        #\n",
    "        self.h1 = self.msk.h_g1\n",
    "        self.auth_template += [g1_add(self.h1[i].scalar_mul(self.r0), self.c[i]) for i in range(self.n) ]\n",
    "        #\n",
    "        self.powers = self.msk.u_vector\n",
    "        self.ProductTemp = \\\n",
    "        Alexa_IPE_Authentication.akaProduct_g1(self.auth_template, self.powers, 0, (self.n + 2), 2, 0)\n",
    "        self.auth_template[0] = self.ProductTemp.scalar_mul(order-1)\n",
    "        #\n",
    "        self.powers = self.msk.v_vector\n",
    "        self.ProductTemp = \\\n",
    "        Alexa_IPE_Authentication.akaProduct_g1(self.auth_template, self.powers, 0, (self.n + 2), 2, 0)\n",
    "        self.auth_template[1] = self.ProductTemp.scalar_mul(order-1)\n",
    "\n",
    "    @staticmethod            \n",
    "    def akaProduct_g1(c_vector, power_vector, j, n, shift_c_index = 0, shift_power_index = 0):\n",
    "        xAkaProduct = c_vector[j + shift_c_index].scalar_mul(power_vector[j + shift_power_index])\n",
    "        for i in range((1+j),n, 1):\n",
    "            temp = c_vector[i + shift_c_index].scalar_mul(power_vector[i + shift_power_index])\n",
    "            xAkaProduct = g1_add(xAkaProduct, temp)\n",
    "            del temp\n",
    "        return xAkaProduct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAlexa_IPE_Authentication = Alexa_IPE_Authentication(xAlexa_IPE_Setup.msk, Alexa_IPE_Setup.vectorOfNumberToVectorOfPoints(v2, G1, invG1), len(v2))\n",
    "assert len(xAlexa_IPE_Authentication.auth_template) == (4 + len(v2)), \" somthing wrong \"\n",
    "assert len(xAlexa_IPE_Authentication.auth_template) == len(xAlexa_IPE_Registration.reg_template), \" somthing wrong \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexa_IPE_Decryption:\n",
    "    \n",
    "    def __init__(self, pairing, g1, g2, reg_template, auth_template):\n",
    "        assert len(auth_template) == len(reg_template) , \" ERORR : templates of different length \"\n",
    "        self.n  = len(auth_template)\n",
    "        self.k = (self.n - 4)\n",
    "        self.G1 = g1\n",
    "        self.G2 = g2\n",
    "        self.pairing = pairing\n",
    "        self.reg_template  = reg_template\n",
    "        self.auth_template = auth_template\n",
    "        self.pairingG2G1 = self.pairing(self.G2, self.G1)\n",
    "        self.pairingOfTemplates = None\n",
    "        self.inner_product = None\n",
    "        self.hamming_dictance = None\n",
    "\n",
    "    def get_inner_product(self):\n",
    "        assert self.pairingOfTemplates is not None\n",
    "        flag = True\n",
    "        xPower = 0\n",
    "        gt_temp     = gt_scalar_mult(self.pairingG2G1, xPower)\n",
    "        if  gt_temp == self.pairingOfTemplates:\n",
    "            self.inner_product =  xPower\n",
    "        else:\n",
    "            xPower += 2\n",
    "            gt_temp2    = gt_scalar_mult(self.pairingG2G1, 2)\n",
    "            gt_temp     = gt_temp2\n",
    "            gt_temp2Inv = gt_temp2.inverse()\n",
    "            gt_tempInv  = gt_temp2Inv\n",
    "            while flag:\n",
    "                if self.k < xPower:\n",
    "                    flag = False\n",
    "                else:\n",
    "                    if  gt_tempInv == self.pairingOfTemplates:\n",
    "                        self.inner_product = -xPower\n",
    "                        flag = False\n",
    "                    elif gt_temp == self.pairingOfTemplates:\n",
    "                        self.inner_product =  xPower\n",
    "                        flag = False\n",
    "                    else:\n",
    "                        gt_temp    = gt_add(gt_temp, gt_temp2)\n",
    "                        gt_tempInv = gt_add(gt_tempInv, gt_temp2Inv)\n",
    "                        pass\n",
    "\n",
    "    def get_hamming_dictance(self):\n",
    "        assert self.inner_product is not None\n",
    "        self.hamming_dictance = ((self.k - self.inner_product) / (2*self.k))\n",
    "                    \n",
    "    def get_pairing_of_templates(self):\n",
    "        self.pairingOfTemplates = Alexa_IPE_Decryption.get_pairing_of_templates_staticmethod(self.pairing, self.reg_template, self.auth_template)\n",
    "                \n",
    "    @staticmethod\n",
    "    def get_pairing_of_templates_staticmethod(pairing, dk_vector, ct_vector):\n",
    "        assert len(dk_vector) == len(ct_vector) , \" ERORR : templates of different length \"\n",
    "        n = len(dk_vector)\n",
    "        pairing_list = [pairing(dk_vector[i], ct_vector[i]) \\\n",
    "                  for i in range(n)]\n",
    "        product = pairing_list[0]\n",
    "        for i in range(1,n, 1):\n",
    "            product = gt_add(product, pairing_list[i])\n",
    "        del pairing_list\n",
    "        return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xAlexa_IPE_Decryption = Alexa_IPE_Decryption(optimal_ate, G1, G2, xAlexa_IPE_Registration.reg_template, xAlexa_IPE_Authentication.auth_template)\n",
    "xAlexa_IPE_Decryption.get_pairing_of_templates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "xAlexa_IPE_Decryption.get_inner_product()\n",
    "print(xAlexa_IPE_Decryption.inner_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "xAlexa_IPE_Decryption.get_hamming_dictance()\n",
    "print(xAlexa_IPE_Decryption.hamming_dictance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alexa_Hamming.inner_product(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Alexa_Hamming.hamming_distance(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xAlexa_IPE_Decryption.inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert Alexa_Hamming.inner_product(v1, v2)    == xAlexa_IPE_Decryption.inner_product, \" error \"\n",
    "assert Alexa_Hamming.hamming_distance(v1, v2) == xAlexa_IPE_Decryption.hamming_dictance, \" error \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
